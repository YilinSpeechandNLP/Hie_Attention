import os
import numpy as np
from keras.callbacks import ModelCheckpoint
from keras.preprocessing.text import Tokenizer
from keras.utils.np_utils import to_categorical

#from keras_bert import Tokenizer
#import keras
#from keras_bert import get_base_dict, get_model, compile_model, gen_batch_inputs

### self defined functions
from src.functions import f1,rc,pr
from src.data_load import embedding_layer_gene,test_data_load
from src.data_load import classification_data_load as load
import pdb
def classification_func(trans_item,model_item,path_item):

    dev_accuracy = []
    dev_f_score = []

    test_lists = os.listdir(path_item.test_transcript_path)
    test_texts = test_data_load(test_lists, path_item.test_transcript_path)
    for idx in range(model_item.Fold):
        print('fold ' + str(idx))
        path_item.res_f.write('fold: ' + str(idx) + '\n')
        ### list prepare
        train_lst_path = os.path.join(path_item.list_dir, str(idx), 'trans_train')
        train_lists = open(train_lst_path).readlines()
        dev_lst_path = os.path.join(path_item.list_dir, str(idx), 'trans_dev')
        dev_lists = open(dev_lst_path).readlines()
        # data load and prepare
        train_labels, train_texts = load(train_lists, path_item.train_transcript_path)
        dev_labels, dev_texts = load(dev_lists, path_item.train_transcript_path)
        class_num = len(set(train_labels+ dev_labels)) # calculate the number of class in the data
        
        train_labels = to_categorical(np.asarray(train_labels), class_num)
        dev_labels = to_categorical(np.asarray(dev_labels), class_num)
        all_texts = train_texts+dev_texts+test_texts
        ## tokenizer initialized
        tokenizer = Tokenizer(num_words=trans_item.max_NB_words)
        tokenizer.fit_on_texts(all_texts)
        # each word correspond to a int number 
        word_index = tokenizer.word_index


        # padding: regular the data format into the requirement matrix
        train_text_matrix = trans_item.matrix_gene(model_item.model_type,train_texts, tokenizer)
        dev_text_matrix =trans_item.matrix_gene(model_item.model_type,dev_texts, tokenizer)
        test_text_matrix = trans_item.matrix_gene(model_item.model_type,test_texts, tokenizer)


        embedding_layer = embedding_layer_gene(word_index, trans_item.embedding_len,path_item.glove_path)
        ## model initialization
        model_folder_ex = os.path.join(path_item.model_folder,model_item.model_type)
        if os.path.exists(model_folder_ex) == False:
            os.makedirs(model_folder_ex)
            
        model_saved_path = os.path.join(model_folder_ex, str(idx))
        model = model_item.model_select(trans_item,embedding_layer)

        checkpoint = ModelCheckpoint(model_saved_path, monitor='val_f1', verbose=2, save_best_only=True,
                                         mode='max', save_weights_only=True)
        model.compile(loss='binary_crossentropy',
                          optimizer='adam',
                          metrics=[pr, rc, f1, 'accuracy'])

        model.fit(train_text_matrix, train_labels,
                  batch_size=model_item.batch_size,
                  epochs=model_item.epochs,
                  validation_data=(dev_text_matrix, dev_labels),
                  callbacks=[checkpoint],
                  shuffle=True)
        model.load_weights(model_saved_path)

        eva_loss, eva_pre, eva_rec, eva_f_m, eva_acc = model.evaluate(dev_text_matrix, dev_labels, batch_size=model_item.batch_size)
        path_item.res_f.write(
                "eva test acc:" + str(round(eva_acc, 4)) + " eva val F-score:" + str(round(eva_f_m, 4)) + '\n\n')
        dev_accuracy.append(eva_acc)
        dev_f_score.append(eva_f_m)

        pred_test_score = model.predict(test_text_matrix)
        pred_test_label = np.argmax(pred_test_score, axis=1)

        pre_dev_scores = model.predict(dev_text_matrix)
        pred_dev_label = np.argmax(pre_dev_scores, axis=1)

        test_dir = os.path.join(path_item.output_test_label,model_item.model_type)
        if os.path.exists(test_dir)==False:
            os.makedirs(test_dir)
        pred_test_f = open(os.path.join(test_dir, 'pred_label-' + str(idx)), 'w')
        pred_test_f.write('name pred_label\n')
        for name, p_label in zip(test_lists, pred_test_label):
            pred_test_f.write(name + ' ' + str(p_label) + '\n')
        pred_test_f.close()
        dev_dir = os.path.join(path_item.output_dev_label,model_item.model_type)
        if os.path.exists(test_dir)==False:
            os.makedirs(dev_dir)
        pred_dev_f = open(os.path.join(dev_dir, 'pred_label-' + str(idx)), 'w')
        pred_dev_f.write('name true_label pred_label \n')
        for name, t_label, p_label in zip(dev_lists, dev_labels, pred_dev_label):
            pred_dev_f.write(name.split(' ')[0] + ' ' +str(t_label)+' ' + str(p_label) + '\n')
            pred_dev_f.close()
    # calcute the criterias for the 9 fold CV
    dev_accuracy = np.asarray(dev_accuracy)
    dev_acc_mean = np.mean(dev_accuracy, axis=0)
    dev_f_score = np.asarray(dev_f_score)
    dev_f_mean = np.mean(dev_f_score, axis=0)

    path_item.res_f.write(
        "average dev accuracy:" + str(round(dev_acc_mean, 4)) + "average dev fmeasure:" + str(
            round(dev_f_mean, 4)) + '\n')
    path_item.res_f.write('********************************\n')
    path_item.res_f.write('********************************\n')
    path_item.res_f.write('********************************\n')
    path_item.res_f.close()